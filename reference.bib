
@article{Allen2015UniVR,
  title={UniVR: A Universal Variance Reduction Framework for Proximal Stochastic Gradient Method},
  author={Allen-Zhu, Zeyuan and Yuan, Yang},
  journal={arXiv preprint arXiv:1506.01972},
  year={2015}
}

@article{Shah2016Trading,
  title={Trading-off variance and complexity in stochastic gradient descent},
  author={Shah, Vatsal and Asteris, Megasthenis and Kyrillidis, Anastasios and Sanghavi, Sujay},
  journal={arXiv preprint arXiv:1603.06861},
  year={2016}
}

@article{ShalevShwartz:2015vw,
  title={SDCA without duality},
  author={Shalev-Shwartz, Shai},
  journal={arXiv preprint arXiv:1502.06177},
  year={2015}
}



@article{AllenZhu:2016up,
  title={Variance reduction for faster non-convex optimization},
  author={Allen-Zhu, Zeyuan and Hazan, Elad},
  journal={arXiv preprint arXiv:1603.05643},
  year={2016}
}




@article{Johnson:9MAvkbgy,
  title={Accelerating Stochastic Gradient Descent using Predictive Variance Reduction},
  author={Johnson, R and Zhang, T},
  journal={Advances in Neural Information Processing Systems},
  pages={315--323},
  year={2013},
}

@article{Richtarik:2013te,
  title={Semi-Stochastic Gradient Descent Methods},
  author={Kone{\v{c}}n{\`y}, Jakub and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1312.1666},
  year={2013}
}


@article{Liu:2015bx,
  title={Mini-batch semi-stochastic gradient descent in the proximal setting},
  author={Kone{\v{c}}n{\`y}, Jakub and Liu, Jie and Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={10},
  number={2},
  pages={242--255},
  year={2016},
  publisher={IEEE}
}

@inproceedings{Zhang2013Linear,
  title={Linear convergence with condition number independent access of full gradients},
  author={Zhang, Lijun and Mahdavi, Mehrdad and Jin, Rong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={980--988},
  year={2013}
}


@article{Li:2016vh,
  title={Stochastic Variance Reduced Optimization for Nonconvex Sparse Learning},
  author={Li, Xingguo and Zhao, Tuo and Arora, Raman and Liu, Han and Haupt, Jarvis},
  journal={arXiv preprint arXiv:1605.02711},
  year={2016}
}

@article{Xiao:2014vw,
  title={A proximal stochastic gradient method with progressive variance reduction},
  author={Xiao, Lin and Zhang, Tong},
  journal={SIAM Journal on Optimization},
  volume={24},
  number={4},
  pages={2057--2075},
  year={2014},
  publisher={SIAM}
}


@article{Allenzhu2016Katyusha,
  title={Katyusha: Accelerated Variance Reduction for Faster SGD},
  author={Allen-Zhu, Zeyuan},
  journal={arXiv preprint arXiv:1603.05953},
  year={2016}
}

@article{Allen2015Improved,
  title={Improved SVRG for non-strongly-convex or sum-of-non-convex objectives},
  author={Allen-Zhu, Zeyuan and Yuan, Yang},
  journal={arXiv preprint arXiv:1506.01972},
  year={2015}
}

@inproceedings{Defazio:2014vu,
  title={Saga: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1646--1654},
  year={2014}
}

@article{Schmidt:2013ui,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Roux, Nicolas Le and Bach, Francis},
  journal={arXiv preprint arXiv:1309.2388},
  year={2013}
}


